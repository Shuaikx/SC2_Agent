# Tactics framework: Synergizing Reinforcement Learning and Large Language Models to Play StarCraft II

StarCraft II, developed by Blizzard Entertainment, is a real-time strategy (RTS) game and is currently one of the most popular electronic sports (eSports) games. The game offers three distinct species: Terran, Zerg, and Protoss. Players can choose among these species to collect resources, construct bases, and build armies for confrontation. Due to its enormous space of strategies, precise operational demands, long-term strategic planning, and asymmetric information game, StarCraft II has emerged as a pivotal platform for testing artificial intelligence capabilities.

![SCII-Structure](https://github.com/Shuaikx/SC2_Agent/blob/main/Images/image1.png)

The extensive exploration of StarCraft II and reinforcement learning has been a hot topic in various AI communities. As early as 2019, DeepMind developed AlphaStar, the pioneering AI capable of comprehensively handling the game, subsequently defeating professional player MANA. The StarCraft Commander (SCC), requires significantly fewer resources and less time for training compared to AlphaStar. Importantly, SCC achieves performance levels that either match those of AlphaStar. This includes a notable triumph against the 2023 World Champion, Time. ROA-Star introduced a novel opponent modelling auxiliary training task, alleviating the problem that AlphaStar could not effectively match an opponent's real-time strategy.  However, traditional Reinforcement Learning agents lack long-term planning in games, and their decision-making process is not interpretable.
